{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "07014239-7d8b-45da-8713-f74341cbb40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import ResMLP\n",
    "import torch\n",
    "model = ResMLP(dropout=0.1, num_residuals_per_block=1, num_blocks=1, num_classes=1,\n",
    "                 num_initial_features=512, last_activation=\"LinearBounded\", min_bound=-1, max_bound=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "275526ad-e7c5-429c-92cb-dbd1a6293d10",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'saved/models/ResMLP/0708_182006/model_best.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-218-f32ee6f4723f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved/models/ResMLP/0708_182006/model_best.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saved/models/ResMLP/0708_182006/model_best.pth'"
     ]
    }
   ],
   "source": [
    "\n",
    "checkpoint = torch.load(\"saved/models/ResMLP/0708_182006/model_best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "982e1d6e-6f6d-4ac4-ab05-ed6ceecadf86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1974]], grad_fn=<ClampBackward1>)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(torch.rand(512).view(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ace3999d-8100-4a30-8fa2-d4ed28a26d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/torch/autograd/__init__.py:149: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class MyActivationFunction(nn.Module):\n",
    "\n",
    "    def __init__(self, mean=0, std=1, min=0.1, max=0.9):\n",
    "        super(MyActivationFunction, self).__init__()\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.min = min\n",
    "        self.max = max\n",
    "\n",
    "    def forward(self, x):\n",
    "        gauss = torch.exp((-(x - self.mean) ** 2)/(2* self.std ** 2))\n",
    "        return torch.clamp(gauss, min=self.min, max=self.max)\n",
    "\n",
    "my_net = nn.Sequential(\n",
    "    nn.Linear(7, 5),\n",
    "    MyActivationFunction()\n",
    ")\n",
    "\n",
    "y = my_net(Variable(torch.rand(10, 7)))\n",
    "y.backward(torch.rand(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "17879df2-8347-4132-a804-838cfdabef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBounded(nn.Module): \n",
    "    def __init__(self, min_bound, max_bound):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert min_bound < max_bound\n",
    "        \n",
    "        self.min_bound = min_bound\n",
    "        self.max_bound = max_bound\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return torch.clamp(x, min=self.min_bound, max=self.max_bound)\n",
    "    \n",
    "class SigmoidBounded(nn.Module):\n",
    "    \n",
    "    def __init__(self, min_bound, max_bound):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert min_bound < max_bound\n",
    "        \n",
    "        self.min_bound = min_bound\n",
    "        self.max_bound = max_bound\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return torch.sigmoid(x) * (self.max_bound - self.min_bound) + self.min_bound\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "98f91a7a-87b4-40da-a063-347e4669e978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0.6693))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = LinearBounded(0, 100)\n",
    "bar = SigmoidBounded(0, 100)\n",
    "\n",
    "x = torch.tensor(-5)\n",
    "foo(x) , bar(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c1d2b311-bc80-4967-91dd-1f12a1505619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(100)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def linear_bounded(x, min_bound=0, max_bound=100):\n",
    "    assert max_bound > min_bound\n",
    "    return torch.clamp(x, min=min_bound, max=max_bound)\n",
    "\n",
    "foo = linear_bounded(torch.tensor(111))\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "286c2bf3-fa94-4b9a-b36b-cbf70f95bd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(26.8941)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(torch.tensor(-1))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2104351c-d5d3-49d4-882e-e1261e09bec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def sigmoid_bounded(x, min_bound=0, max_bound=100):\n",
    "    assert max_bound > min_bound\n",
    "    return torch.sigmoid(x) * (max_bound - min_bound) + min_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "59548ab9-4216-40ae-ae0d-4aec51b6cc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-123.)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_bounded(torch.tensor(-100000000000), min_bound=-123, max_bound=101.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3a0b0035-6eda-4763-9e1a-1380e7085b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def trucated_gaussian(x, mean=0, std=1, min=0.1, max=0.9):\n",
    "    gauss = torch.exp((-(x - mean) ** 2)/(2* std ** 2))\n",
    "    return torch.clamp(gauss, min=min, max=max) # truncate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dfadbfd9-ed47-4d12-85d8-dbfb4bed2751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader.data_loaders import AgeDataLoader\n",
    "\n",
    "dl = AgeDataLoader(data_dir='./data', batch_size=128, shuffle=True, validation_split=0.1,\n",
    "                 num_workers=8, dataset='imdb_wiki', num_classes=101, training=True, test_cross_val=None,\n",
    "                 limit_data=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "96e336e0-740c-42b5-b684-f0865d65a604",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (data, target) in enumerate(dl):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "81364742-0468-45df-abf1-9a4ffb05bae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.float32(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "722d5494-0763-409b-9d6f-a4ed13dea3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([44., 30., 37., 35., 59., 49., 38., 29., 30., 35., 38., 37., 52.,  1.,\n",
       "        41., 31., 31., 46., 48., 47., 25., 49., 14., 17., 49., 77., 39., 14.,\n",
       "        26., 25., 42., 38., 24., 38., 52., 25., 37., 33., 34., 24., 21., 28.,\n",
       "        30., 67., 38., 21., 37., 24., 44., 25., 21., 31., 28., 72., 24., 46.,\n",
       "        40., 65., 35., 32., 27., 39., 35., 26., 38., 32., 40., 20., 33., 44.,\n",
       "        43., 35., 33., 35., 27., 33., 21., 35., 57., 42., 38., 70., 23., 25.,\n",
       "        23., 32., 47., 46., 18., 24., 24., 46., 23., 46., 31., 35., 27., 37.,\n",
       "        42., 21., 31., 31., 34., 42., 45., 47., 28., 47., 60., 46., 47., 20.,\n",
       "        34., 34., 35., 50., 23., 30., 31., 22., 30., 28., 36., 36., 48., 30.,\n",
       "        35., 25.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8c56d3cf-9c01-4daf-8585-5c67a614a334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 512]), torch.Size([128]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8a5bfebf-0079-4e3d-a1a6-fd33b63f9ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5000, 2.3000])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d42a71b2-fb95-4d66-99e9-944c227f94a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2]) torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def accuracy(output, target):\n",
    "    with torch.no_grad():\n",
    "        assert output.shape[0] == len(target)\n",
    "        correct = 0\n",
    "        correct += torch.sum(((output-target).abs() <= 0.5)).item()\n",
    "    return correct / len(target)\n",
    "\n",
    "output = torch.tensor([1.1, 2.2])\n",
    "target = torch.tensor([1.5, 2.3])\n",
    "\n",
    "print(output.shape, target.shape)\n",
    "\n",
    "accuracy(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6d9dd1a2-c075-4bee-826c-d3d11f4dfaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e4288881-a4a8-49a7-86a3-afa48e0de344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(((output-target).abs() <= 0.5)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b4543ae-3f10-4cd9-b674-818e946ffd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def accuracy(output, target):\n",
    "    with torch.no_grad():\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        assert pred.shape[0] == len(target)\n",
    "\n",
    "        correct = 0\n",
    "        for p, t in zip(pred, target):\n",
    "            if (0 <= p <= 2) and (0 <= t <= 2):\n",
    "                correct+=1\n",
    "            elif (4 <= p <= 6) and (4 <= t <= 6):\n",
    "                correct+=1\n",
    "            elif (8 <= p <= 12) and (8 <= t <= 12):\n",
    "                correct+=1\n",
    "            elif (15 <= p <= 20) and (15 <= t <= 20):\n",
    "                correct+=1\n",
    "            elif (25 <= p <= 32) and (25 <= t <= 32):\n",
    "                correct+=1\n",
    "            elif (38 <= p <= 43) and (38 <= t <= 43):\n",
    "                correct+=1\n",
    "            elif (48 <= p <= 53) and (48 <= t <= 53):\n",
    "                correct+=1\n",
    "            elif (60 <= p <= 100) and (60 <= t <= 100):\n",
    "                correct+=1\n",
    "            else:\n",
    "                raise ValueError\n",
    "    return correct / len(target)\n",
    "\n",
    "output = torch.tensor([[1,2,3], [2,3,4]])\n",
    "target = torch.tensor([2, 1])\n",
    "\n",
    "# print(output.shape, target.shape)\n",
    "\n",
    "accuracy(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "742430fc-d942-43d8-bd17-e72e8615830b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1< torch.tensor(1) < 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3189f496-7861-460d-a4bc-64ff33d6aba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb5e3093-cc9f-42d4-9259-4180e44f676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import ResMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30d87eae-017c-477f-b34e-0a3af49bbdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResMLP(dropout=0.5, num_residuals_per_block=1, num_blocks=3, num_classes=2,\n",
    "                 num_initial_features=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b412ccb-11e8-4ea0-9e03-85de6be0fa17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Residual(\n",
       "    (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (norm_layer2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout2): Dropout(p=0.5, inplace=False)\n",
       "    (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (relu2): ReLU()\n",
       "  )\n",
       "  (1): DownSample(\n",
       "    (norm_layer): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (2): Residual(\n",
       "    (norm_layer1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout1): Dropout(p=0.5, inplace=False)\n",
       "    (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (norm_layer2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout2): Dropout(p=0.5, inplace=False)\n",
       "    (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (relu2): ReLU()\n",
       "  )\n",
       "  (3): DownSample(\n",
       "    (norm_layer): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linear): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (4): Residual(\n",
       "    (norm_layer1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout1): Dropout(p=0.5, inplace=False)\n",
       "    (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (norm_layer2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout2): Dropout(p=0.5, inplace=False)\n",
       "    (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (relu2): ReLU()\n",
       "  )\n",
       "  (5): DownSample(\n",
       "    (norm_layer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linear): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (6): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dddf7f00-ecff-4ebb-b608-2b4bf3c70372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8192"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a4741cd-ed38-4b56-a4ee-2fceb854976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "data_dir ='./data'\n",
    "data_imdb = np.load(os.path.join(data_dir, f\"imdb_crop/data.npy\"),\n",
    "               allow_pickle=True)\n",
    "data_wiki = np.load(os.path.join(data_dir, f\"wiki_crop/data.npy\"),\n",
    "               allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5534f036-70e9-4972-94a9-a6b4aa4c06c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((356779,), (41472,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_imdb.shape, data_wiki.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfc56c8c-5647-40b0-a8f8-ab2e70e5aabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358425.9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((data_imdb, data_wiki)).shape[0]*0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbab787a-098c-4151-bee4-96503f49984b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "  \"update your install command.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f575f62-2dbc-4edc-904d-d46a911438ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=\"./data\"):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=True, download=True, transform=transform)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197cc520-087a-4f7f-85ad-95590088df98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, l1=120, l2=84):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n",
    "        self.fc2 = nn.Linear(l1, l2)\n",
    "        self.fc3 = nn.Linear(l2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f61aad77-2f37-43af-88dc-139bad20ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cifar(config, checkpoint_dir=None, data_dir=None):\n",
    "    net = Net(config[\"l1\"], config[\"l2\"])\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    trainset, testset = load_data(data_dir)\n",
    "\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=8)\n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=8)\n",
    "\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
    "                                                running_loss / epoch_steps))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "097be01f-a70b-42fb-9530-19626ffb0243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(net, device=\"cpu\"):\n",
    "    trainset, testset = load_data()\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c566e4ba-f908-49a1-bda9-2b4027b0068c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-06 20:00:16,783\tINFO services.py:1274 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2021-07-06 20:00:18,502\tWARNING experiment.py:294 -- No name detected on trainable. Using DEFAULT.\n",
      "2021-07-06 20:00:18,503\tINFO registry.py:65 -- Detected unknown callable for trainable. Converting to class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.5/62.6 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 2.0/16 CPUs, 0/1 GPUs, 0.0/33.11 GiB heap, 0.0/16.55 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/tk/ray_results/DEFAULT_2021-07-06_20-00-18\n",
      "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
      "+---------------------+----------+-------+--------------+------+------+-------------+\n",
      "| Trial name          | status   | loc   |   batch_size |   l1 |   l2 |          lr |\n",
      "|---------------------+----------+-------+--------------+------+------+-------------|\n",
      "| DEFAULT_06256_00000 | RUNNING  |       |            8 |  128 |   16 | 0.000143629 |\n",
      "| DEFAULT_06256_00001 | PENDING  |       |            2 |  256 |    8 | 0.00042884  |\n",
      "| DEFAULT_06256_00002 | PENDING  |       |           16 |   32 |   16 | 0.00626568  |\n",
      "| DEFAULT_06256_00003 | PENDING  |       |            8 |    4 |   32 | 0.00144249  |\n",
      "| DEFAULT_06256_00004 | PENDING  |       |           16 |   64 |   16 | 0.00141633  |\n",
      "| DEFAULT_06256_00005 | PENDING  |       |            2 |  256 |    8 | 0.00658804  |\n",
      "| DEFAULT_06256_00006 | PENDING  |       |            8 |  256 |   32 | 0.00148974  |\n",
      "| DEFAULT_06256_00007 | PENDING  |       |           16 |    8 |   64 | 0.000975269 |\n",
      "| DEFAULT_06256_00008 | PENDING  |       |            4 |    4 |   16 | 0.000269813 |\n",
      "| DEFAULT_06256_00009 | PENDING  |       |            8 |   32 |    8 | 0.00197779  |\n",
      "+---------------------+----------+-------+--------------+------+------+-------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=877590)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=877596)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=877593)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=877600)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=877595)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=877599)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=877598)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=877597)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=877590)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=877599)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=877600)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=877595)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=877596)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=877593)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=877598)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=877597)\u001b[0m Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=877590)\u001b[0m /home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "\u001b[2m\u001b[36m(pid=877590)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[2m\u001b[36m(pid=877599)\u001b[0m /home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "\u001b[2m\u001b[36m(pid=877599)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[2m\u001b[36m(pid=877600)\u001b[0m /home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "\u001b[2m\u001b[36m(pid=877600)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[2m\u001b[36m(pid=877598)\u001b[0m /home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "\u001b[2m\u001b[36m(pid=877598)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[2m\u001b[36m(pid=877595)\u001b[0m /home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "\u001b[2m\u001b[36m(pid=877595)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[2m\u001b[36m(pid=877597)\u001b[0m /home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "\u001b[2m\u001b[36m(pid=877597)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[2m\u001b[36m(pid=877596)\u001b[0m /home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "\u001b[2m\u001b[36m(pid=877596)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[2m\u001b[36m(pid=877593)\u001b[0m /home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "\u001b[2m\u001b[36m(pid=877593)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 14.7/62.6 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 16.0/16 CPUs, 0/1 GPUs, 0.0/33.11 GiB heap, 0.0/16.55 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/tk/ray_results/DEFAULT_2021-07-06_20-00-18\n",
      "Number of trials: 10/10 (2 PENDING, 8 RUNNING)\n",
      "+---------------------+----------+-------+--------------+------+------+-------------+\n",
      "| Trial name          | status   | loc   |   batch_size |   l1 |   l2 |          lr |\n",
      "|---------------------+----------+-------+--------------+------+------+-------------|\n",
      "| DEFAULT_06256_00000 | RUNNING  |       |            8 |  128 |   16 | 0.000143629 |\n",
      "| DEFAULT_06256_00001 | RUNNING  |       |            2 |  256 |    8 | 0.00042884  |\n",
      "| DEFAULT_06256_00002 | RUNNING  |       |           16 |   32 |   16 | 0.00626568  |\n",
      "| DEFAULT_06256_00003 | RUNNING  |       |            8 |    4 |   32 | 0.00144249  |\n",
      "| DEFAULT_06256_00004 | RUNNING  |       |           16 |   64 |   16 | 0.00141633  |\n",
      "| DEFAULT_06256_00005 | RUNNING  |       |            2 |  256 |    8 | 0.00658804  |\n",
      "| DEFAULT_06256_00006 | RUNNING  |       |            8 |  256 |   32 | 0.00148974  |\n",
      "| DEFAULT_06256_00007 | RUNNING  |       |           16 |    8 |   64 | 0.000975269 |\n",
      "| DEFAULT_06256_00008 | PENDING  |       |            4 |    4 |   16 | 0.000269813 |\n",
      "| DEFAULT_06256_00009 | PENDING  |       |            8 |   32 |    8 | 0.00197779  |\n",
      "+---------------------+----------+-------+--------------+------+------+-------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Memory usage on this node: 14.7/62.6 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 16.0/16 CPUs, 0/1 GPUs, 0.0/33.11 GiB heap, 0.0/16.55 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/tk/ray_results/DEFAULT_2021-07-06_20-00-18\n",
      "Number of trials: 10/10 (2 PENDING, 8 RUNNING)\n",
      "+---------------------+----------+-------+--------------+------+------+-------------+\n",
      "| Trial name          | status   | loc   |   batch_size |   l1 |   l2 |          lr |\n",
      "|---------------------+----------+-------+--------------+------+------+-------------|\n",
      "| DEFAULT_06256_00000 | RUNNING  |       |            8 |  128 |   16 | 0.000143629 |\n",
      "| DEFAULT_06256_00001 | RUNNING  |       |            2 |  256 |    8 | 0.00042884  |\n",
      "| DEFAULT_06256_00002 | RUNNING  |       |           16 |   32 |   16 | 0.00626568  |\n",
      "| DEFAULT_06256_00003 | RUNNING  |       |            8 |    4 |   32 | 0.00144249  |\n",
      "| DEFAULT_06256_00004 | RUNNING  |       |           16 |   64 |   16 | 0.00141633  |\n",
      "| DEFAULT_06256_00005 | RUNNING  |       |            2 |  256 |    8 | 0.00658804  |\n",
      "| DEFAULT_06256_00006 | RUNNING  |       |            8 |  256 |   32 | 0.00148974  |\n",
      "| DEFAULT_06256_00007 | RUNNING  |       |           16 |    8 |   64 | 0.000975269 |\n",
      "| DEFAULT_06256_00008 | PENDING  |       |            4 |    4 |   16 | 0.000269813 |\n",
      "| DEFAULT_06256_00009 | PENDING  |       |            8 |   32 |    8 | 0.00197779  |\n",
      "+---------------------+----------+-------+--------------+------+------+-------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=877593)\u001b[0m [1,  2000] loss: 2.306\n",
      "\u001b[2m\u001b[36m(pid=877595)\u001b[0m [1,  2000] loss: 2.216\n",
      "\u001b[2m\u001b[36m(pid=877599)\u001b[0m [1,  2000] loss: 2.127\n",
      "\u001b[2m\u001b[36m(pid=877590)\u001b[0m [1,  2000] loss: 2.301\n",
      "\u001b[2m\u001b[36m(pid=877597)\u001b[0m [1,  2000] loss: 2.199\n",
      "\u001b[2m\u001b[36m(pid=877598)\u001b[0m [1,  2000] loss: 2.254\n",
      "\u001b[2m\u001b[36m(pid=877600)\u001b[0m [1,  2000] loss: 1.830\n",
      "\u001b[2m\u001b[36m(pid=877596)\u001b[0m [1,  2000] loss: 2.127\n",
      "\u001b[2m\u001b[36m(pid=877593)\u001b[0m [1,  4000] loss: 1.117\n",
      "Result for DEFAULT_06256_00007:\n",
      "  accuracy: 0.2743\n",
      "  date: 2021-07-06_20-00-42\n",
      "  done: false\n",
      "  experiment_id: 18be9b768bb64e65a61f055b172f0dc2\n",
      "  hostname: xps17\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.934524203491211\n",
      "  node_ip: 192.168.0.151\n",
      "  pid: 877598\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 22.59846830368042\n",
      "  time_this_iter_s: 22.59846830368042\n",
      "  time_total_s: 22.59846830368042\n",
      "  timestamp: 1625594442\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: '06256_00007'\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.6/62.6 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.934524203491211\n",
      "Resources requested: 16.0/16 CPUs, 0/1 GPUs, 0.0/33.11 GiB heap, 0.0/16.55 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/tk/ray_results/DEFAULT_2021-07-06_20-00-18\n",
      "Number of trials: 10/10 (2 PENDING, 8 RUNNING)\n",
      "+---------------------+----------+----------------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
      "| Trial name          | status   | loc                  |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
      "|---------------------+----------+----------------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
      "| DEFAULT_06256_00000 | RUNNING  |                      |            8 |  128 |   16 | 0.000143629 |         |            |                      |\n",
      "| DEFAULT_06256_00001 | RUNNING  |                      |            2 |  256 |    8 | 0.00042884  |         |            |                      |\n",
      "| DEFAULT_06256_00002 | RUNNING  |                      |           16 |   32 |   16 | 0.00626568  |         |            |                      |\n",
      "| DEFAULT_06256_00003 | RUNNING  |                      |            8 |    4 |   32 | 0.00144249  |         |            |                      |\n",
      "| DEFAULT_06256_00004 | RUNNING  |                      |           16 |   64 |   16 | 0.00141633  |         |            |                      |\n",
      "| DEFAULT_06256_00005 | RUNNING  |                      |            2 |  256 |    8 | 0.00658804  |         |            |                      |\n",
      "| DEFAULT_06256_00006 | RUNNING  |                      |            8 |  256 |   32 | 0.00148974  |         |            |                      |\n",
      "| DEFAULT_06256_00007 | RUNNING  | 192.168.0.151:877598 |           16 |    8 |   64 | 0.000975269 | 1.93452 |     0.2743 |                    1 |\n",
      "| DEFAULT_06256_00008 | PENDING  |                      |            4 |    4 |   16 | 0.000269813 |         |            |                      |\n",
      "| DEFAULT_06256_00009 | PENDING  |                      |            8 |   32 |    8 | 0.00197779  |         |            |                      |\n",
      "+---------------------+----------+----------------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
      "\n",
      "\n",
      "Result for DEFAULT_06256_00002:\n",
      "  accuracy: 0.4475\n",
      "  date: 2021-07-06_20-00-42\n",
      "  done: false\n",
      "  experiment_id: 23d365dae9f643ebb8c50fc74d549a69\n",
      "  hostname: xps17\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.4956548726081849\n",
      "  node_ip: 192.168.0.151\n",
      "  pid: 877600\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 22.721685647964478\n",
      "  time_this_iter_s: 22.721685647964478\n",
      "  time_total_s: 22.721685647964478\n",
      "  timestamp: 1625594442\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: '06256_00002'\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=877595)\u001b[0m [1,  4000] loss: 1.086\n",
      "Result for DEFAULT_06256_00004:\n",
      "  accuracy: 0.3643\n",
      "  date: 2021-07-06_20-00-43\n",
      "  done: true\n",
      "  experiment_id: 4da3f6b2c5484adfa6322c8b98364f82\n",
      "  hostname: xps17\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.7364599870681763\n",
      "  node_ip: 192.168.0.151\n",
      "  pid: 877596\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 23.299724102020264\n",
      "  time_this_iter_s: 23.299724102020264\n",
      "  time_total_s: 23.299724102020264\n",
      "  timestamp: 1625594443\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: '06256_00004'\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=877599)\u001b[0m [1,  4000] loss: 0.878\n",
      "\u001b[2m\u001b[36m(pid=877591)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=877590)\u001b[0m [1,  4000] loss: 1.134\n",
      "\u001b[2m\u001b[36m(pid=877591)\u001b[0m Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=877591)\u001b[0m /home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "\u001b[2m\u001b[36m(pid=877591)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=877597)\u001b[0m [1,  4000] loss: 0.865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-06 20:00:51,059\tWARNING tune.py:507 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=877593)\u001b[0m [1,  6000] loss: 0.693\n"
     ]
    }
   ],
   "source": [
    "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n",
    "    data_dir = os.path.abspath(\"./data\")\n",
    "    load_data(data_dir)\n",
    "    config = {\n",
    "        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
    "        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\": tune.choice([2, 4, 8, 16])\n",
    "    }\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    reporter = CLIReporter(\n",
    "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        partial(train_cifar, data_dir=data_dir),\n",
    "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change the number of GPUs per trial here:\n",
    "    main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c34bd06-293f-47b7-80c9-43bbf6702218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
